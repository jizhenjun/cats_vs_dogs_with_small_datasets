# cats_vs_dogs

数据集：kaggle 猫狗大战
训练集：https://www.kaggle.com/jizhenjun/cats-vs-dogs-with-small-datasets train_after_crop文件夹
验证集：https://www.kaggle.com/c/dogs-vs-cats/data validation_with_group文件夹

## 模型说明
k_1_dnn_250_250.h5 dnn模型，img_size为250*250，5折验证
k_2_dnn_250_250.h5 dnn模型，img_size为250*250，5折验证
k_3_dnn_250_250.h5 dnn模型，img_size为250*250，5折验证
k_4_dnn_250_250.h5 dnn模型，img_size为250*250，5折验证
k_5_dnn_250_250.h5 dnn模型，img_size为250*250，5折验证

## 模型下载
链接: https://pan.baidu.com/s/1hIJVAX082FM6WaVI25paUg 提取码: fd76

## 实验结果解读

### 实验目标
阅读keras文档中的小数据集深度学习一文，了解目前能到达的精度，  
发现在借助迁移学习的前提下，能轻松到达百分之94的准确率。  
但是迁移学习的数据集是imagenet，含有猫狗，因此提出问题，不借助迁移学习能将精度提高到多少

### 实验准备
数据集选择了猫狗各1000张图片，模型选择keras文档中的三层卷积网络模型、alexnet与17层的cnn网络。
超参数方面，经过简单试验初步选择，决定采用dnn与(250,250)的图像大小。  
从试验结果来看，越深的网络适用的图像大小越大，数据增广对小数据集的提升极大

### 数据清洗
用作者本人开发的bbox工具将图片中的猫狗裁剪出，并剔除一部分有问题的训练数据。  
从原始数据来看，猫的图片中影响结果的噪声较多（比如人的手），狗相对好一些

###第一次训练
采用5折验证，每一次的训练集准确率能到达98%，验证集准确率为88%-90%，从验证集的结果来看，  
模型提取的姿态方面的特征较多，对光照与猫狗的部位细节的特征提取的较为不好.  
若将特征向量用svm进行分类，准确率大概为78%.  

### 进一步优化
细粒度图像分类模型(MASK_CNN,双线性CNN)

### 第二次训练


## 实验结论
优化器无脑adam，最后一层激活函数无脑sigmoid（二分类），batch_size设成2的幂。  
数据增广和bbox效果拔群，图像大小和网络的深度正相关，